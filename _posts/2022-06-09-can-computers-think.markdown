---
layout: post
title:  Can Computers Think?
categories: Philosophy
tags: AI Intelligence Conciousness
share: True
comments: True
---

As technology continues to advance at an exponential rate, the question of whether computers can think has become increasingly relevant. From simple arithmetic calculations to playing e-games and generating artworks, computers are now able to perform tasks that were once thought to be the exclusive domain of human intelligence. Although these tasks are impossible to perform without “thinking”, the question “Can computers think?” is still up for debate. Of course, the answer depends on how we define the term “thinking”. Using the dictionary definition of the word would be naïve since it would generate more questions than answers. Thus to get closer to answers, the concept of “thinking” must be objective and concrete.

Turing dispensed with the definition of the term and proposed the Turing test [[1](https://redirect.cs.umbc.edu/courses/471/papers/turing.pdf)], according to which, a computer could be said to “think” if a human interrogator, through conversation, couldn’t differentiate it from a human being. The Turing test’s concept fascinates me because, in my opinion, the doubt that computers could think would vanish if they could accomplish all the tasks humans do, without revealing that they are, in fact, an Artificial Intelligence (AI) system. So, the following section attempts the answer with the Turing test as a starting point.

# Answering based on the Turing Test

Since the question “Can Computers think?” also considers future possibilities, I firmly believe that computers will be able to imitate and outperform humans in nearly every task that can be evaluated from outside. Computers already perform on par with humans on various tasks such as playing e-games, solving arithmetic, generating artworks, language translation, and many more. Of course, there are certain areas in which humans still excel, such as visual reasoning, multi-chain reasoning, and adaptability to new situations. However, with the rapid advancement of AI and deep learning technologies, it seems that it may only be a matter of time before computers are able to surpass human capabilities in these areas as well. In fact, it is my belief that computers will eventually be able to imitate and outperform humans in nearly every task that can be evaluated from the outside. The speed with which they process data, combined with their ability to learn and adapt, makes it increasingly likely that they will be able to compete with humans in areas that were previously thought to be solely within the realm of human intelligence.

Some critics of the Turing test argue that computers’ high speed and accuracy will reveal themselves to the interrogator. This argument overlooks the fact that computers participating in the Turing test can be specifically programmed to imitate humans so that they deliberately make mistakes and slower responses. While this may seem counterintuitive, given the primary purpose of computers is to perform tasks efficiently and accurately, it is possible and also crucial for computers to convincingly mimic humans. Therefore, the ability of a computers to deceive an interrogator during the Turing test cannot be dismissed as a mere byproduct of their inherent capabilities.

People claim that a particular computer is better suited for certain tasks only. Humans, on contrary, have a broad spectrum of intelligence. So, across diverse tasks, humans will outshine computers. Turing contended that this limitation is due to the small storage capacity of computers, which limits their ability to perform a broad range of tasks [[1](https://redirect.cs.umbc.edu/courses/471/papers/turing.pdf)]. I believe that computers have the potential to exhibit intelligence similar to that of humans. By combining multiple single-task programs into one computer and building a decider that determines which program is most suited to answer a particular question, we can potentially overcome the limitations imposed by small storage capacity.

Many contend that computers can only perform what they are programmed to. Hence they can neither invent, nor choose their own problem. Therefore, humans will outshine Turing machines on the account of creativity. This contention ignores the fact that only a few extraordinary humans invent or choose their own problems. Minsky posited that outstanding minds differ from ordinary minds only in terms of degree [[2](https://ojs.aaai.org/index.php/aimagazine/article/view/376)]. Thus, if we agree that computers can do tasks of ordinary intelligence, then it is only a matter of time before we see them creating breakthroughs in various disciplines. Deepmind has already demonstrated that AI can discover theorems and formulate hypotheses at the forefront of science [[3](https://www.nature.com/articles/s41586-021-04086-x), [4](https://www.science.org/doi/10.1126/science.abj6511), [5](https://www.nature.com/articles/s41586-021-03819-2)]. Additionally, to those who claim that computers can’t be creative, it is possible to respond that creativity doesn’t exist in the first place since everything we create is derived or at least inspired by something that already exists.

<div class="row mt-3">
    <div class="col-sm">
        {% include figure.html path="assets/img/can_computers_think.png" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Fig 1. Robot mixing sparkling chemicals
</div>

# Critique of the Turing Test

However, many believe that simply defining “thinking” as the ability to pass the Turing test is not enough. They argue that intelligence and consciousness are two separate strands associated with "thinking”. They concede that the Turing test does well in evaluating intelligence, but it is hopeless in evaluating consciousness. These individuals argue that simply displaying intelligent behavior does not necessarily imply that a computer is sentient, or truly conscious. That is, the emulation of consciousness might not be true consciousness. For example, a language model may be able to form logical sentences by predicting the next word based on probability, but it may not truly understand or feel the meaning of the words it is using. With the Chinese room argument [[6](https://web-archive.southampton.ac.uk/cogprints.org/7150/1/10.1.1.83.5248.pdf)], Searle suggests that computers merely manipulate symbol strings using syntactic rules, but have no concept of meaning or semantics. However, Turing rebutted that the only way to justify sentience in computers is by being the computers themselves. In my opinion, we perceive other fellow humans as conscious because we share a similar substrate and project our own consciousness onto them. Hence we find meaning and purpose in what they do or say. However, we would never have that substrate equivalence with computers and thus would never fully accept that they are conscious, even if they truly are.

# Gödel’s Incompleteness Theorem and its implications

Gödel’s incompleteness theorem [[7](https://link.springer.com/article/10.1007/BF01700692)] is one of the most important result in the field of mathematical logic, and it has significant implications for our understanding of the limitations of computers and other formal systems. In 1931, Gödel proved that in any consistent formal system F, there are true statements S(F) (called Gödel sentence) which can neither be proved nor disproved using the rules in F. Computers, if they are consistent, are also subject to this limitation. However, humans can prove the validity of Gödel’s unprovable result. Pouncing on this idea, Penrose and others argued that the human mind is non-algorithmic and hence is not a consistent Turing machine [[8](https://www.cambridge.org/core/journals/philosophy/article/minds-machines-and-godel1/727219EDEB5DD3679E56CF3D335C90C1), [9](https://www.amazon.com/Shadows-Mind-Missing-Science-Consciousness/dp/0195106466)]. This argument is famous as the Lucas-Penrose argument.

Turing himself argued that humans could be subject to the same limitations that formal systems are. He believed that humans can answer questions that computers cannot because we have a deeper understanding of how computers operate and the limitations of their programming [[1](https://redirect.cs.umbc.edu/courses/471/papers/turing.pdf)]. Additionally, since no formal system can prove its consistency from within itself [[7](https://link.springer.com/article/10.1007/BF01700692)], many argue that humans, if they are formal systems, also will not be able to ascertain their consistency. In this view, there is a possibility that humans are inconsistent Turing machines for which Lucas-Penrose’s argument does not hold [[10](https://philarchive.org/rec/PUTMAM), [11](https://www.openstarts.units.it/bitstream/10077/5474/1/Hutton_E&P_V_2003_1.pdf)]. Another perspective is offered by philosopher Paul Benacerraf, who contends that the formal system implemented by the human mind may be so complex that we may never be able to construct our own version of a Gödel sentence [[12](https://www.jstor.org/stable/27902014)]. If this is the case, then perhaps we are not different from machines; we might be complicated Turing machines, but Turing machines nonetheless.

# Conclusion

To summarize, the ongoing debate over whether computers can think is a complex and multifaceted, and will likely continue to evolve as technology advances. Regardless of where one falls in this debate, it is clear that computers are rapidly becoming more advanced and sophisticated. Considering the capabilities of computers and the rapid advancement of AI and deep learning technologies, I think it isn't bold to claim that computers, conscious or not, will match human intellect behaviourally. Although I acknowledge that consciousness is essential, it remains a mystery and falls under the realm of philosophy. It would be meaningful to introduce the subject of consciousness in scientific discussion only when we can prove its presence or absence.

# References

1. [A. M. Turing, "Computing machinery and intelligence," in Parsing the turing test, Springer, 2009, pp. 23–65.](https://redirect.cs.umbc.edu/courses/471/papers/turing.pdf)
2. [M. L. Minsky, “Why people think computers can’t,” AI magazine, vol. 3, no. 4, pp. 3–3, 1982](https://ojs.aaai.org/index.php/aimagazine/article/view/376)
3. [A. Davies et al., “Advancing mathematics by guiding human intuition with ai,” Nature, vol. 600, no. 7887, pp. 70–74, 2021.](https://www.nature.com/articles/s41586-021-04086-x)
4. [J. Kirkpatrick et al., “Pushing the frontiers of density functionals by solving the fractional electron problem,” Science, vol. 374, no. 6573, pp. 1385–1389, 2021.](https://www.science.org/doi/10.1126/science.abj6511)
5. [J. Jumper et al., “Highly accurate protein structure prediction with alphafold,” Nature, vol. 596, no. 7873, pp. 583–589, 2021](https://www.nature.com/articles/s41586-021-03819-2)
6. [J. R. Searle, “Minds, brains, and programs,” Behavioral and brain sciences, vol. 3, no. 3, pp. 417–424, 1980.](https://web-archive.southampton.ac.uk/cogprints.org/7150/1/10.1.1.83.5248.pdf)
7. [K. Gödel, “Über formal unentscheidbare sätze der principia mathematica und verwandter systeme i,” Monatshefte für mathematik und physik, vol. 38, no. 1, pp. 173–198, 1931.](https://link.springer.com/article/10.1007/BF01700692)
8. [J. R. Lucas, “Minds, machines and gödel1,” Philosophy, vol. 36, no. 137, pp. 112–127, 1961.](https://www.cambridge.org/core/journals/philosophy/article/minds-machines-and-godel1/727219EDEB5DD3679E56CF3D335C90C1)
9. [R. Penrose, Shadows of the Mind. Oxford University Press Oxford, 1994, vol. 4.](https://www.amazon.com/Shadows-Mind-Missing-Science-Consciousness/dp/0195106466)
10. [H. Putnam, “Minds and machines,” 1960.](https://philarchive.org/rec/PUTMAM)
11. [A. Hutton, “This gödel is killing me,” 1976.](https://www.openstarts.units.it/bitstream/10077/5474/1/Hutton_E&P_V_2003_1.pdf)
12. [P. Benacerraf, “God, the devil, and gödel,” The monist, pp. 9–32, 1967.](https://www.jstor.org/stable/27902014)
