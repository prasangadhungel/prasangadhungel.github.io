<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Can Computers Think? | Prasanga Dhungel</title> <meta name="author" content="Prasanga Dhungel"> <meta name="description" content="Master's in Informatics at the Technical University of Munich (TUM), a Deep Learning Enthusiast "> <meta name="keywords" content="Prasanga, Prasanga, Deep Learning, AI, Mathematics"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700%7CRoboto+Slab:100,300,400,500,700%7CMaterial+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon-800.webp"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://prasangadhungel.github.io/blog/2022/can-computers-think/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Prasanga </span>Dhungel</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/contact/">Contact</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Can Computers Think?</h1> <p class="post-meta">June 9, 2022</p> <p class="post-tags"> <a href="/blog/2022"> <i class="fas fa-calendar fa-sm"></i> 2022 </a>   ·   <a href="/blog/tag/ai"> <i class="fas fa-hashtag fa-sm"></i> AI</a>   <a href="/blog/tag/intelligence"> <i class="fas fa-hashtag fa-sm"></i> Intelligence</a>   <a href="/blog/tag/conciousness"> <i class="fas fa-hashtag fa-sm"></i> Conciousness</a>     ·   <a href="/blog/category/philosophy"> <i class="fas fa-tag fa-sm"></i> Philosophy</a>   </p> </header> <article class="post-content"> <p>As technology continues to advance at an exponential rate, the question of whether computers can think has become increasingly relevant. From simple arithmetic calculations to playing e-games and generating artworks, computers are now able to perform tasks that were once thought to be the exclusive domain of human intelligence. Although these tasks are impossible to perform without “thinking”, the question “Can computers think?” is still up for debate. Of course, the answer depends on how we define the term “thinking”. Using the dictionary definition of the word would be naïve since it would generate more questions than answers. Thus to get closer to answers, the concept of “thinking” must be objective and concrete.</p> <p>Turing dispensed with the definition of the term and proposed the Turing test [<a href="https://redirect.cs.umbc.edu/courses/471/papers/turing.pdf" rel="external nofollow noopener" target="_blank">1</a>], according to which, a computer could be said to “think” if a human interrogator, through conversation, couldn’t differentiate it from a human being. The Turing test’s concept fascinates me because, in my opinion, the doubt that computers could think would vanish if they could accomplish all the tasks humans do, without revealing that they are, in fact, an Artificial Intelligence (AI) system. So, the following section attempts the answer with the Turing test as a starting point.</p> <h1 id="answering-based-on-the-turing-test">Answering based on the Turing Test</h1> <p>Since the question “Can Computers think?” also considers future possibilities, I firmly believe that computers will be able to imitate and outperform humans in nearly every task that can be evaluated from outside. Computers already perform on par with humans on various tasks such as playing e-games, solving arithmetic, generating artworks, language translation, and many more. Of course, there are certain areas in which humans still excel, such as visual reasoning, multi-chain reasoning, and adaptability to new situations. However, with the rapid advancement of AI and deep learning technologies, it seems that it may only be a matter of time before computers are able to surpass human capabilities in these areas as well. In fact, it is my belief that computers will eventually be able to imitate and outperform humans in nearly every task that can be evaluated from the outside. The speed with which they process data, combined with their ability to learn and adapt, makes it increasingly likely that they will be able to compete with humans in areas that were previously thought to be solely within the realm of human intelligence.</p> <p>Some critics of the Turing test argue that computers’ high speed and accuracy will reveal themselves to the interrogator. This argument overlooks the fact that computers participating in the Turing test can be specifically programmed to imitate humans so that they deliberately make mistakes and slower responses. While this may seem counterintuitive, given the primary purpose of computers is to perform tasks efficiently and accurately, it is possible and also crucial for computers to convincingly mimic humans. Therefore, the ability of a computers to deceive an interrogator during the Turing test cannot be dismissed as a mere byproduct of their inherent capabilities.</p> <p>People claim that a particular computer is better suited for certain tasks only. Humans, on contrary, have a broad spectrum of intelligence. So, across diverse tasks, humans will outshine computers. Turing contended that this limitation is due to the small storage capacity of computers, which limits their ability to perform a broad range of tasks [<a href="https://redirect.cs.umbc.edu/courses/471/papers/turing.pdf" rel="external nofollow noopener" target="_blank">1</a>]. I believe that computers have the potential to exhibit intelligence similar to that of humans. By combining multiple single-task programs into one computer and building a decider that determines which program is most suited to answer a particular question, we can potentially overcome the limitations imposed by small storage capacity.</p> <p>Many contend that computers can only perform what they are programmed to. Hence they can neither invent, nor choose their own problem. Therefore, humans will outshine Turing machines on the account of creativity. This contention ignores the fact that only a few extraordinary humans invent or choose their own problems. Minsky posited that outstanding minds differ from ordinary minds only in terms of degree [<a href="https://ojs.aaai.org/index.php/aimagazine/article/view/376" rel="external nofollow noopener" target="_blank">2</a>]. Thus, if we agree that computers can do tasks of ordinary intelligence, then it is only a matter of time before we see them creating breakthroughs in various disciplines. Deepmind has already demonstrated that AI can discover theorems and formulate hypotheses at the forefront of science [<a href="https://www.nature.com/articles/s41586-021-04086-x" rel="external nofollow noopener" target="_blank">3</a>, <a href="https://www.science.org/doi/10.1126/science.abj6511" rel="external nofollow noopener" target="_blank">4</a>, <a href="https://www.nature.com/articles/s41586-021-03819-2" rel="external nofollow noopener" target="_blank">5</a>]. Additionally, to those who claim that computers can’t be creative, it is possible to respond that creativity doesn’t exist in the first place since everything we create is derived or at least inspired by something that already exists.</p> <div class="row mt-3"> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/can_computers_think-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/can_computers_think-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/can_computers_think-1400.webp"></source> <img src="/assets/img/can_computers_think.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Fig 1. Robot mixing sparkling chemicals </div> <h1 id="critique-of-the-turing-test">Critique of the Turing Test</h1> <p>However, many believe that simply defining “thinking” as the ability to pass the Turing test is not enough. They argue that intelligence and consciousness are two separate strands associated with “thinking”. They concede that the Turing test does well in evaluating intelligence, but it is hopeless in evaluating consciousness. These individuals argue that simply displaying intelligent behavior does not necessarily imply that a computer is sentient, or truly conscious. That is, the emulation of consciousness might not be true consciousness. For example, a language model may be able to form logical sentences by predicting the next word based on probability, but it may not truly understand or feel the meaning of the words it is using. With the Chinese room argument [<a href="https://web-archive.southampton.ac.uk/cogprints.org/7150/1/10.1.1.83.5248.pdf" rel="external nofollow noopener" target="_blank">6</a>], Searle suggests that computers merely manipulate symbol strings using syntactic rules, but have no concept of meaning or semantics. However, Turing rebutted that the only way to justify sentience in computers is by being the computers themselves. In my opinion, we perceive other fellow humans as conscious because we share a similar substrate and project our own consciousness onto them. Hence we find meaning and purpose in what they do or say. However, we would never have that substrate equivalence with computers and thus would never fully accept that they are conscious, even if they truly are.</p> <h1 id="gödels-incompleteness-theorem-and-its-implications">Gödel’s Incompleteness Theorem and its implications</h1> <p>Gödel’s incompleteness theorem [<a href="https://link.springer.com/article/10.1007/BF01700692" rel="external nofollow noopener" target="_blank">7</a>] is one of the most important result in the field of mathematical logic, and it has significant implications for our understanding of the limitations of computers and other formal systems. In 1931, Gödel proved that in any consistent formal system F, there are true statements S(F) (called Gödel sentence) which can neither be proved nor disproved using the rules in F. Computers, if they are consistent, are also subject to this limitation. However, humans can prove the validity of Gödel’s unprovable result. Pouncing on this idea, Penrose and others argued that the human mind is non-algorithmic and hence is not a consistent Turing machine [<a href="https://www.cambridge.org/core/journals/philosophy/article/minds-machines-and-godel1/727219EDEB5DD3679E56CF3D335C90C1" rel="external nofollow noopener" target="_blank">8</a>, <a href="https://www.amazon.com/Shadows-Mind-Missing-Science-Consciousness/dp/0195106466" rel="external nofollow noopener" target="_blank">9</a>]. This argument is famous as the Lucas-Penrose argument.</p> <p>Turing himself argued that humans could be subject to the same limitations that formal systems are. He believed that humans can answer questions that computers cannot because we have a deeper understanding of how computers operate and the limitations of their programming [<a href="https://redirect.cs.umbc.edu/courses/471/papers/turing.pdf" rel="external nofollow noopener" target="_blank">1</a>]. Additionally, since no formal system can prove its consistency from within itself [<a href="https://link.springer.com/article/10.1007/BF01700692" rel="external nofollow noopener" target="_blank">7</a>], many argue that humans, if they are formal systems, also will not be able to ascertain their consistency. In this view, there is a possibility that humans are inconsistent Turing machines for which Lucas-Penrose’s argument does not hold [<a href="https://philarchive.org/rec/PUTMAM" rel="external nofollow noopener" target="_blank">10</a>, <a href="https://www.openstarts.units.it/bitstream/10077/5474/1/Hutton_E&amp;P_V_2003_1.pdf" rel="external nofollow noopener" target="_blank">11</a>]. Another perspective is offered by philosopher Paul Benacerraf, who contends that the formal system implemented by the human mind may be so complex that we may never be able to construct our own version of a Gödel sentence [<a href="https://www.jstor.org/stable/27902014" rel="external nofollow noopener" target="_blank">12</a>]. If this is the case, then perhaps we are not different from machines; we might be complicated Turing machines, but Turing machines nonetheless.</p> <h1 id="conclusion">Conclusion</h1> <p>To summarize, the ongoing debate over whether computers can think is a complex and multifaceted, and will likely continue to evolve as technology advances. Regardless of where one falls in this debate, it is clear that computers are rapidly becoming more advanced and sophisticated. Considering the capabilities of computers and the rapid advancement of AI and deep learning technologies, I think it isn’t bold to claim that computers, conscious or not, will match human intellect behaviourally. Although I acknowledge that consciousness is essential, it remains a mystery and falls under the realm of philosophy. It would be meaningful to introduce the subject of consciousness in scientific discussion only when we can prove its presence or absence.</p> <h1 id="references">References</h1> <ol> <li><a href="https://redirect.cs.umbc.edu/courses/471/papers/turing.pdf" rel="external nofollow noopener" target="_blank">A. M. Turing, “Computing machinery and intelligence,” in Parsing the turing test, Springer, 2009, pp. 23–65.</a></li> <li><a href="https://ojs.aaai.org/index.php/aimagazine/article/view/376" rel="external nofollow noopener" target="_blank">M. L. Minsky, “Why people think computers can’t,” AI magazine, vol. 3, no. 4, pp. 3–3, 1982</a></li> <li><a href="https://www.nature.com/articles/s41586-021-04086-x" rel="external nofollow noopener" target="_blank">A. Davies et al., “Advancing mathematics by guiding human intuition with ai,” Nature, vol. 600, no. 7887, pp. 70–74, 2021.</a></li> <li><a href="https://www.science.org/doi/10.1126/science.abj6511" rel="external nofollow noopener" target="_blank">J. Kirkpatrick et al., “Pushing the frontiers of density functionals by solving the fractional electron problem,” Science, vol. 374, no. 6573, pp. 1385–1389, 2021.</a></li> <li><a href="https://www.nature.com/articles/s41586-021-03819-2" rel="external nofollow noopener" target="_blank">J. Jumper et al., “Highly accurate protein structure prediction with alphafold,” Nature, vol. 596, no. 7873, pp. 583–589, 2021</a></li> <li><a href="https://web-archive.southampton.ac.uk/cogprints.org/7150/1/10.1.1.83.5248.pdf" rel="external nofollow noopener" target="_blank">J. R. Searle, “Minds, brains, and programs,” Behavioral and brain sciences, vol. 3, no. 3, pp. 417–424, 1980.</a></li> <li><a href="https://link.springer.com/article/10.1007/BF01700692" rel="external nofollow noopener" target="_blank">K. Gödel, “Über formal unentscheidbare sätze der principia mathematica und verwandter systeme i,” Monatshefte für mathematik und physik, vol. 38, no. 1, pp. 173–198, 1931.</a></li> <li><a href="https://www.cambridge.org/core/journals/philosophy/article/minds-machines-and-godel1/727219EDEB5DD3679E56CF3D335C90C1" rel="external nofollow noopener" target="_blank">J. R. Lucas, “Minds, machines and gödel1,” Philosophy, vol. 36, no. 137, pp. 112–127, 1961.</a></li> <li><a href="https://www.amazon.com/Shadows-Mind-Missing-Science-Consciousness/dp/0195106466" rel="external nofollow noopener" target="_blank">R. Penrose, Shadows of the Mind. Oxford University Press Oxford, 1994, vol. 4.</a></li> <li><a href="https://philarchive.org/rec/PUTMAM" rel="external nofollow noopener" target="_blank">H. Putnam, “Minds and machines,” 1960.</a></li> <li><a href="https://www.openstarts.units.it/bitstream/10077/5474/1/Hutton_E&amp;P_V_2003_1.pdf" rel="external nofollow noopener" target="_blank">A. Hutton, “This gödel is killing me,” 1976.</a></li> <li><a href="https://www.jstor.org/stable/27902014" rel="external nofollow noopener" target="_blank">P. Benacerraf, “God, the devil, and gödel,” The monist, pp. 9–32, 1967.</a></li> </ol> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0 text-center"> © Copyright 2023 Prasanga Dhungel. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>
